{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo /lab/users/Cruz/vivian/LearnRAN/KFold Classifier/KFold_v1.ini existe.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Author: Vivian Maria da Silva e Souza \n",
    "Instutution: Coppe Del UFRJ\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score)\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "configuration_file = '/lab/users/Cruz/vivian/LearnRAN/KFold Classifier/KFold_v1.ini'\n",
    " \n",
    "if os.path.exists(configuration_file):\n",
    "    print(f\"O arquivo {configuration_file} existe.\")\n",
    "else:\n",
    "    print(f\"O arquivo {configuration_file} n√£o foi encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(configuration_file)\n",
    "for section in config.sections():\n",
    "    print(f\"[{section}]\")\n",
    "    for key, value in config.items(section):\n",
    "        print(f\"{key} = {value}\")\n",
    "    print()\n",
    "\n",
    "rome_slow_close_dir = config['DEFAULT']['rome_slow_close']\n",
    "rome_static_close_dir = config['DEFAULT']['rome_static_close']\n",
    "rome_static_far_dir = config['DEFAULT']['rome_static_far']\n",
    "rome_static_medium_dir = config['DEFAULT']['rome_static_medium']\n",
    "embb_ues = config['DEFAULT']['default_embb_ues']\n",
    "mtc_ues = config['DEFAULT']['default_mtc_ues']\n",
    "urllc_ues = config['DEFAULT']['default_urllc_ues']\n",
    "\n",
    "possible_cases = [rome_slow_close_dir, rome_static_close_dir, rome_static_far_dir, rome_static_medium_dir]\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "\n",
    "classifier = GaussianNB()\n",
    "ues = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing (data_list,n_ue):\n",
    "    dl_mcs, dl_brate, ul_mcs, ul_brate = 0,0,0,0\n",
    "    last_time = 0\n",
    "    for j in range (1,len(data_list)):\n",
    "        time_interval = data_list[j][0] - data_list[j-1][0]\n",
    "        if np.isinf(data_list[j-1][1]) or np.isinf(data_list[j-1][2]) or np.isinf(data_list[j-1][3]) or np.isinf(data_list[j-1][4]): continue \n",
    "        last_time += time_interval\n",
    "        dl_mcs += data_list[j-1][1] * time_interval\n",
    "        dl_brate += data_list[j-1][2] * time_interval\n",
    "        ul_mcs += data_list[j-1][3] * time_interval\n",
    "        ul_brate += data_list[j-1][4] * time_interval\n",
    "\n",
    "    dl_mcs = dl_mcs/last_time\n",
    "    dl_brate = dl_brate/last_time\n",
    "    ul_mcs = ul_mcs/last_time\n",
    "    ul_brate = ul_brate/last_time                  \n",
    "    data = [dl_mcs, dl_brate, ul_mcs, ul_brate]\n",
    "\n",
    "    if str(n_ue) in mtc_ues: \n",
    "        class_ue = 'embb'\n",
    "    elif str(n_ue) in mtc_ues:\n",
    "        class_ue = 'mtc'\n",
    "    else: \n",
    "        class_ue = 'urllc'\n",
    "    return data,class_ue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wished_cols = [0,7,10,13,15]\n",
    "for n_tr in range (18):\n",
    "    tr = 'tr' + str(n_tr) + '/'\n",
    "    for n_exp in range (1,7): \n",
    "        exp = 'exp' + str (n_exp) + '/'\n",
    "        for n_ue in range (1,41):\n",
    "            if n_ue%10 != 0: \n",
    "                n_bs = n_ue//10 + 1\n",
    "            else: \n",
    "                n_bs = n_ue//10 \n",
    "            bs = 'bs' + str (n_bs) + '/'\n",
    "            a = 'ue'+str(n_ue)+'.csv'\n",
    "            for traffic_case in possible_cases:\n",
    "                try:\n",
    "                    inf_ue = pd.read_csv(traffic_case+tr+exp+bs+a, skiprows=1, usecols = wished_cols,dtype=np.float64)\n",
    "                    inf_ue = np.array(inf_ue)\n",
    "                    data = data_processing (inf_ue,n_ue)\n",
    "                    ues[traffic_case+tr+exp+bs+a] = data\n",
    "                except FileNotFoundError: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_used (b):\n",
    "    ue_data, ue_classes = [],[]\n",
    "\n",
    "    all_samples = list(ues.keys())\n",
    "    all_labels = [value[1] for value in ues.values()]  \n",
    "\n",
    "    used_samples, notused_samples, used_labels, notused_labels = train_test_split(\n",
    "    all_samples, all_labels, test_size=1/3, stratify=all_labels, random_state=b)\n",
    "\n",
    "    ues_used = {sample: ues[sample] for sample in used_samples}\n",
    "    ues_notused = {sample: ues[sample] for sample in notused_samples}\n",
    "\n",
    "    for n in ues_used:\n",
    "        ue_data.append(ues_used[n][0])\n",
    "        ue_classes.append(ues_used[n][1])\n",
    "\n",
    "    return ue_data,ue_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_classifier (a,k_fold,b):\n",
    "    n = data_used (b)\n",
    "    ue_data_classifier = n[0]\n",
    "    ue_classes_classifier = n[1]\n",
    "    ue_data_classifier = np.array(ue_data_classifier)\n",
    "    ue_classes_classifier = np.array(ue_classes_classifier)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=a)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    for train_index, test_index in kf.split(ue_data_classifier,ue_classes_classifier):\n",
    "        data_train, data_test = ue_data_classifier[train_index], ue_data_classifier[test_index]\n",
    "        class_train, class_test = ue_classes_classifier[train_index], ue_classes_classifier[test_index]\n",
    "        classifier.fit(data_train, class_train)\n",
    "        predictions = classifier.predict(data_test)\n",
    "        accuracy = accuracy_score(predictions,class_test)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrixes = confusion_matrix(class_test, predictions, labels=[\"embb\", \"mtc\", \"urllc\"])\n",
    "        print (confusion_matrixes)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    print (accuracy_scores)\n",
    "    result = str(mean_accuracy) + ' ; ' + str(std_accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mcs_embb, dl_mcs_mtc, dl_mcs_urllc = [],[],[]\n",
    "dl_brate_embb, dl_brate_mtc, dl_brate_urllc = [],[],[]  \n",
    "ul_mcs_embb, ul_mcs_mtc, ul_mcs_urllc = [],[],[]\n",
    "ul_brate_embb, ul_brate_mtc, ul_brate_urllc = [],[],[]\n",
    "\n",
    "for d,n in ues.values():\n",
    "    if n == 'embb':\n",
    "        dl_mcs_embb.append(d[0])\n",
    "        dl_brate_embb.append(d[1])\n",
    "        ul_mcs_embb.append(d[2])\n",
    "        ul_brate_embb.append(d[3])\n",
    "    if n == 'mtc':\n",
    "        dl_mcs_mtc.append(d[0])\n",
    "        dl_brate_mtc.append(d[1])\n",
    "        ul_mcs_mtc.append(d[2])\n",
    "        ul_brate_mtc.append(d[3])\n",
    "    else:\n",
    "        dl_mcs_urllc.append(d[0])\n",
    "        dl_brate_urllc.append(d[1])\n",
    "        ul_mcs_urllc.append(d[2])\n",
    "        ul_brate_urllc.append(d[3])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 741  132  297]\n",
      " [   6  654  259]\n",
      " [   4    0 1249]]\n",
      "[[ 730  148  291]\n",
      " [   4  652  263]\n",
      " [   6    0 1247]]\n",
      "[[ 735  140  294]\n",
      " [   3  661  255]\n",
      " [   2    0 1251]]\n",
      "[0.7911430281268701, 0.7868901526489075, 0.7922777611493564]\n",
      "0.7901036473083779 ; 0.0023190250398122626\n"
     ]
    }
   ],
   "source": [
    "print(gb_classifier (8,3,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
