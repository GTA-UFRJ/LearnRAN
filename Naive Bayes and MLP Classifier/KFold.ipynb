{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo C:\\Users\\vivia\\.vscode\\cli\\LearnRan\\KFold_v1.ini existe.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Author: Vivian Maria da Silva e Souza \n",
    "Instutution: Coppe Del UFRJ\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score)\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "configuration_file = 'C:\\\\Users\\\\vivia\\\\.vscode\\\\cli\\\\LearnRan\\\\KFold_v1.ini'\n",
    " \n",
    "if os.path.exists(configuration_file):\n",
    "    print(f\"O arquivo {configuration_file} existe.\")\n",
    "else:\n",
    "    print(f\"O arquivo {configuration_file} não foi encontrado.\")\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(configuration_file)\n",
    "for section in config.sections():\n",
    "    print(f\"[{section}]\")\n",
    "    for key, value in config.items(section):\n",
    "        print(f\"{key} = {value}\")\n",
    "    print()\n",
    "\n",
    "rome_slow_close_dir = config['DEFAULT']['rome_slow_close']\n",
    "rome_static_close_dir = config['DEFAULT']['rome_static_close']\n",
    "rome_static_far_dir = config['DEFAULT']['rome_static_far']\n",
    "rome_static_medium_dir = config['DEFAULT']['rome_static_medium']\n",
    "embb_ues = config['DEFAULT']['default_embb_ues']\n",
    "mtc_ues = config['DEFAULT']['default_mtc_ues']\n",
    "urllc_ues = config['DEFAULT']['default_urllc_ues']\n",
    "\n",
    "possible_cases = [rome_slow_close_dir, rome_static_close_dir, rome_static_far_dir, rome_static_medium_dir]\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "\n",
    "classifier = GaussianNB()\n",
    "ues, ues_av = {},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rates_classifier (data_list,n_ue):\n",
    "    dl_brate, ul_brate = [],[]\n",
    "    weights_times = []\n",
    "    data = []\n",
    "    for j in range (1,len(data_list)):\n",
    "        time_interval = data_list[j][0] - data_list[j-1][0]\n",
    "        if np.isinf(data_list[j-1][1]) or np.isinf(data_list[j-1][2]): continue \n",
    "        data.append(data_list[j][1:])\n",
    "        weights_times.append(time_interval)\n",
    "        dl_brate.append(data_list[j-1][1])\n",
    "        ul_brate.append(data_list[j-1][2])\n",
    "    weights_times = np.array(weights_times)\n",
    "    dl_brate_av = np.average(dl_brate, weights=weights_times)\n",
    "    dl_brate_std = np.std(dl_brate) \n",
    "    ul_brate_av =  np.average(ul_brate, weights=weights_times)         \n",
    "    ul_brate_std = np.std(ul_brate) \n",
    "    data_av = [dl_brate_av, dl_brate_std, ul_brate_av, ul_brate_std]\n",
    "\n",
    "    if str(n_ue) in embb_ues: \n",
    "        class_ue = 'embb'\n",
    "    elif str(n_ue) in mtc_ues:\n",
    "        class_ue = 'mtc'\n",
    "    else: \n",
    "        class_ue = 'urllc'\n",
    "    return data_av,class_ue,data,class_ue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening files and calling calculate_rates_classifier \n",
    "\n",
    "wished_cols = [0,10,15]\n",
    "for n_tr in range (18):\n",
    "    tr = 'tr' + str(n_tr) + '\\\\'\n",
    "    for n_exp in range (1,7): \n",
    "        exp = 'exp' + str (n_exp) + '\\\\'\n",
    "        for n_ue in range (1,41):\n",
    "            if n_ue%10 != 0: \n",
    "                n_bs = n_ue//10 + 1\n",
    "            else: \n",
    "                n_bs = n_ue//10 \n",
    "            bs = 'bs' + str (n_bs) + '\\\\'\n",
    "            a = 'ue'+str(n_ue)+'.csv'\n",
    "            for traffic_case in possible_cases:\n",
    "                try:\n",
    "                    inf_ue = pd.read_csv(traffic_case+tr+exp+bs+a, skiprows=1, usecols = wished_cols,dtype=np.float64, memory_map=True)\n",
    "                    inf_ue = np.array(inf_ue)\n",
    "                    data = calculate_rates_classifier (inf_ue,n_ue)\n",
    "                    ues_av[traffic_case+tr+exp+bs+a] = data[:2]\n",
    "                    ues[traffic_case+tr+exp+bs+a] = data[2:]\n",
    "                except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_len (dic):\n",
    "    len_max = 0\n",
    "    for i in dic: \n",
    "        if len(dic[i]) > len_max: len_max = len(dic[i])\n",
    "    for n in dic:\n",
    "        while len(dic[n]) < len_max:\n",
    "            n = np.append(dic[n], [0,0])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_used (b,ues):\n",
    "    ue_data, ue_classes = [],[]\n",
    "    len = []\n",
    "    ues_sl = same_len(ues)\n",
    "    all_samples = list(ues_sl.keys())\n",
    "    all_labels = [value[1] for value in ues_sl.values()]  \n",
    "\n",
    "    used_samples, notused_samples, used_labels, notused_labels = train_test_split(\n",
    "    all_samples, all_labels, test_size=1/3, stratify=all_labels, random_state=b)\n",
    "\n",
    "    ues_used = {sample: ues_sl[sample] for sample in used_samples}\n",
    "    ues_notused = {sample: ues_sl[sample] for sample in notused_samples}\n",
    "\n",
    "    for n in ues_used:\n",
    "        ue_data.append(ues_used[n][0])\n",
    "        ue_classes.append(ues_used[n][1])\n",
    "\n",
    "    return ue_data,ue_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold (a, k_fold,b,ue):\n",
    "    datas_train, datas_test, classes_train, classes_test = [],[],[],[]\n",
    "    n = data_used (b,ue)\n",
    "    ue_data_classifier = n[0]\n",
    "    ue_classes_classifier = n[1]\n",
    "    ue_data_classifier = np.array(ue_data_classifier)\n",
    "    ue_classes_classifier = np.array(ue_classes_classifier)\n",
    "    kf = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=a)\n",
    "    for train_index, test_index in kf.split(ue_data_classifier,ue_classes_classifier):\n",
    "        data_train, data_test = ue_data_classifier[train_index], ue_data_classifier[test_index]\n",
    "        class_train, class_test = ue_classes_classifier[train_index], ue_classes_classifier[test_index]\n",
    "        datas_test.append(data_test)\n",
    "        datas_train.append(data_train)\n",
    "        classes_test.append(class_test)\n",
    "        classes_train.append(class_train)\n",
    "    return datas_train,classes_train,datas_test,classes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_classifier (a,k_fold,b):\n",
    "    kf = kfold (a, k_fold, b, ues_av)\n",
    "    data_train = kf[0]\n",
    "    data_test = kf[2]\n",
    "    class_train = kf[1]\n",
    "    class_test = kf[3]\n",
    "    accuracy_scores = []\n",
    "    for i in range(3):\n",
    "        classifier.fit(data_train[i], class_train[i])\n",
    "        predictions = classifier.predict(data_test[i])\n",
    "        accuracy = accuracy_score(predictions,class_test[i])\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrixes = confusion_matrix(class_test[i], predictions, labels=[\"embb\", \"mtc\", \"urllc\"])\n",
    "        print (confusion_matrixes)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    print (accuracy_scores)\n",
    "    result = str(mean_accuracy) + ' ; ' + str(std_accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_classifier_only_av (a,k_fold,b):\n",
    "    kf = kfold (a, k_fold, b, ues_av)\n",
    "    for i in range (len(kf[0])):\n",
    "        for n in range (len(kf[0][i])):\n",
    "            kf[0][i][n] = [kf[0][i][n][0]] + [0] + [kf[0][i][n][2]] + [0]\n",
    "    for i in range (len(kf[2])):\n",
    "        for n in range (len(kf[2][i])):\n",
    "            kf[2][i][n] = [kf[2][i][n][0]] + [0] + [kf[2][i][n][2]] + [0]\n",
    "    data_train = kf[0]\n",
    "    data_test = kf[2]\n",
    "    class_train = kf[1]\n",
    "    class_test = kf[3]\n",
    "    accuracy_scores = []\n",
    "    for i in range(3):\n",
    "        classifier.fit(data_train[i], class_train[i])\n",
    "        predictions = classifier.predict(data_test[i])\n",
    "        accuracy = accuracy_score(predictions,class_test[i])\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrixes = confusion_matrix(class_test[i], predictions, labels=[\"embb\", \"mtc\", \"urllc\"])\n",
    "        print (confusion_matrixes)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    print (accuracy_scores)\n",
    "    result = str(mean_accuracy) + ' ; ' + str(std_accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_classifier (a,k_fold,b,n):\n",
    "    mlp_gs = MLPClassifier(max_iter=n)\n",
    "    parameter_space = { 'hidden_layer_sizes': [(100,100,100,100,100,100,100,100,100,100)],\n",
    "                        'activation': ['tanh', 'relu'], 'solver': ['adam'], 'alpha': [0.1, 0.01, 0.0001, 0.05], \n",
    "                        'learning_rate': ['constant','adaptive'], }\n",
    "    clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=6)\n",
    "   \n",
    "    kf = kfold (a, k_fold, b, ues_av)\n",
    "    data_train = kf[0]\n",
    "    data_test = kf[2]\n",
    "    class_train = kf[1]\n",
    "    class_test = kf[3]\n",
    "    accuracy_scores = []\n",
    "    for i in range(3):\n",
    "        clf.fit(data_train[i], class_train[i])\n",
    "        predictions = clf.predict(data_test[i])\n",
    "        accuracy = accuracy_score(predictions,class_test[i])\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrixes = confusion_matrix(class_test[i], predictions, labels=[\"embb\", \"mtc\", \"urllc\"])\n",
    "        print (confusion_matrixes)\n",
    "        print()\n",
    "        print('Best parameters found:\\n', clf.best_params_,'nº iterations',str(n))\n",
    "        print()\n",
    "        y_true, y_pred = class_test[i] , predictions\n",
    "        print('Results on the test set:')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    print (accuracy_scores)\n",
    "    result = str(mean_accuracy) + ' ; ' + str(std_accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier (a,k_fold,b):\n",
    "    kf = kfold (a, k_fold, b,ues)\n",
    "    datas_train = kf[0]\n",
    "    datas_test = kf[2]\n",
    "    classes_train = kf[1]\n",
    "    classes_test = kf[3]\n",
    "    centroid_classifier = NearestCentroid()\n",
    "    accuracy_scores = []\n",
    "    for i in range(k_fold):\n",
    "        data_train = datas_train[i]\n",
    "        data_test = datas_test[i]\n",
    "        class_train = classes_train[i]\n",
    "        class_test = classes_test[i]\n",
    "        centroid_classifier.fit(data_train,class_train.values.ravel())\n",
    "        predictions = centroid_classifier.predict(data_test)\n",
    "        print(predictions)\n",
    "        accuracy = accuracy_score(predictions,class_test)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        confusion_matrixes = confusion_matrix(class_test, predictions, labels=[\"embb\", \"mtc\", \"urllc\"])\n",
    "        print (confusion_matrixes)\n",
    "        print(f\"Model Classification Report : \\n{classification_report(class_test, predictions)}\")\n",
    "\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    print (accuracy_scores)\n",
    "    result = str(mean_accuracy) + ' ; ' + str(std_accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes - entradas com média\n",
      "[[ 738  133  299]\n",
      " [   7  672  240]\n",
      " [   1    0 1252]]\n",
      "[[ 738  135  296]\n",
      " [   4  656  259]\n",
      " [   1    0 1252]]\n",
      "[[ 744  149  276]\n",
      " [   0  635  284]\n",
      " [   6    0 1247]]\n",
      "[0.7965290245362059, 0.7919784495659982, 0.7859922178988327]\n",
      "0.7914998973336789 ; 0.004314922379189178\n"
     ]
    }
   ],
   "source": [
    "print ('Naive bayes - entradas com média')\n",
    "print (gb_classifier_only_av(1,3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes - entradas com média e desvio padrão\n",
      "[[ 836  125  209]\n",
      " [   2  752  165]\n",
      " [   0   15 1238]]\n",
      "[[ 846  122  201]\n",
      " [   2  712  205]\n",
      " [   0   25 1228]]\n",
      "[[ 866  123  180]\n",
      " [   1  701  217]\n",
      " [   3   16 1234]]\n",
      "[0.8456014362657092, 0.8338820712361569, 0.838371744986531]\n",
      "0.8392850841627991 ; 0.004827802848235949\n"
     ]
    }
   ],
   "source": [
    "print ('Naive bayes - entradas com média e desvio padrão')\n",
    "print (gb_classifier(1,3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "[[ 935  131  104]\n",
      " [  28  857   34]\n",
      " [  17   50 1186]]\n",
      "\n",
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100, 100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'} nº iterations 200\n",
      "\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        embb       0.95      0.80      0.87      1170\n",
      "         mtc       0.83      0.93      0.88       919\n",
      "       urllc       0.90      0.95      0.92      1253\n",
      "\n",
      "    accuracy                           0.89      3342\n",
      "   macro avg       0.89      0.89      0.89      3342\n",
      "weighted avg       0.90      0.89      0.89      3342\n",
      "\n",
      "[[ 938  114  117]\n",
      " [  28  820   71]\n",
      " [  21   27 1205]]\n",
      "\n",
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100, 100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'} nº iterations 200\n",
      "\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        embb       0.95      0.80      0.87      1169\n",
      "         mtc       0.85      0.89      0.87       919\n",
      "       urllc       0.87      0.96      0.91      1253\n",
      "\n",
      "    accuracy                           0.89      3341\n",
      "   macro avg       0.89      0.89      0.88      3341\n",
      "weighted avg       0.89      0.89      0.89      3341\n",
      "\n",
      "[[ 979   97   93]\n",
      " [  73  801   45]\n",
      " [  30   19 1204]]\n",
      "\n",
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100, 100, 100, 100, 100, 100, 100, 100, 100), 'learning_rate': 'constant', 'solver': 'adam'} nº iterations 200\n",
      "\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        embb       0.90      0.84      0.87      1169\n",
      "         mtc       0.87      0.87      0.87       919\n",
      "       urllc       0.90      0.96      0.93      1253\n",
      "\n",
      "    accuracy                           0.89      3341\n",
      "   macro avg       0.89      0.89      0.89      3341\n",
      "weighted avg       0.89      0.89      0.89      3341\n",
      "\n",
      "[0.891083183722322, 0.8868602214905716, 0.8931457647410955]\n",
      "0.8903630566513296 ; 0.0026160976966127128\n"
     ]
    }
   ],
   "source": [
    "print ('MLP')\n",
    "print (mlp_classifier(1,3,5,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print ('KNN')\n",
    "#print (knn_classifier(1,3,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
